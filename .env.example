# OpenSUSE Ceph Cluster - Environment Configuration
# Copy this file to .env and customize for your environment
# Usage: cp .env.example .env

# ====================
# PROXMOX CONFIGURATION
# ====================

# Proxmox API credentials
# Option 1: Password authentication
export PROXMOX_API_USER="root@pam"
export PROXMOX_API_PASSWORD="your_password_here"
# Option 2: API Token authentication (recommended for automation)
# export PROXMOX_API_USER="root@pam!tokenid"
# export PROXMOX_API_PASSWORD="your-token-secret-here"

export PROXMOX_API_HOST="proxmox.example.com"
export PROXMOX_NODE="pve"  # Usually matches hostname - check with: ssh root@HOST "hostname"

# Proxmox SSH access
export PROXMOX_SSH_USER="root"
# export PROXMOX_SSH_KEY="~/.ssh/id_rsa"  # Auto-detected (id_ed25519 or id_rsa)

# ====================
# IMAGE CONFIGURATION
# ====================

# IMPORTANT: OPENSUSE_IMAGE_PATH must be the FULL PATH including filename
# Do NOT set it to just a directory - it must include the .qcow2 filename
#
# The image directory and filename are automatically extracted from this path:
#   Directory: $(dirname OPENSUSE_IMAGE_PATH)
#   Filename:  $(basename OPENSUSE_IMAGE_PATH)
#
# Common locations:
#   /var/lib/vz/template/iso/opensuse-leap-custom.qcow2         - ISO storage (default)
#   /var/lib/vz/template/qemu/opensuse-leap-custom.qcow2        - VM template storage
#   /mnt/pve/storage/template/opensuse-leap-custom.qcow2        - Custom storage
#   /your-storage/path/opensuse-leap-custom.qcow2               - Custom location
#
# Example: If you set OPENSUSE_IMAGE_PATH="/wdred/iso/template/opensuse-leap-custom.qcow2"
#   - Image directory will be: /wdred/iso/template/
#   - Image filename will be: opensuse-leap-custom.qcow2
export OPENSUSE_IMAGE_PATH="/var/lib/vz/template/iso/opensuse-leap-custom.qcow2"

# Advanced: Override just the image name (optional, rarely needed)
# If not set, the name is automatically extracted from OPENSUSE_IMAGE_PATH
# Only set this if you want a different name than what's in the path above
# export OPENSUSE_IMAGE_NAME="custom-name.qcow2"

# Build directory for KIWI on Proxmox (or build VM)
# This is where KIWI performs the actual image creation
# Defaults to /root/kiwi
export KIWI_BUILD_DIR="/root/kiwi"

# ====================
# IMAGE LOCALIZATION
# ====================

# Keyboard layout for the image (default: uk)
# Common values: uk, us, de, fr, es, etc.
# Note: This is the keyboard layout in the virtual console
export KIWI_KEYTABLE="uk"

# Locale for the image (default: en_GB)
# Common values: en_GB, en_US, de_DE, fr_FR, etc.
export KIWI_LOCALE="en_GB"

# Timezone for the image (default: Europe/London)
# Common values: Europe/London, America/New_York, UTC, etc.
# Use 'timedatectl list-timezones' for full list
export KIWI_TIMEZONE="Europe/London"

# ====================
# BUILD VM CONFIGURATION (RECOMMENDED)
# ====================

# Dedicated OpenSUSE VM for building KIWI images
# This is the RECOMMENDED approach as KIWI works best on OpenSUSE
# The build VM runs on Proxmox and creates images that are transferred back

# Build VM settings
export BUILD_VM_ID="100"                    # VM ID for build VM (MUST be unique!)
                                            # Check available IDs:
                                            #   ssh proxmox 'qm list'   # VMs
                                            #   ssh proxmox 'pct list'  # Containers
                                            # Change if ID 100 is already in use by VM or container
export BUILD_VM_NAME="kiwi-builder"         # VM name
export BUILD_VM_MEMORY="4096"               # 4GB RAM for building (4GB minimum, 8GB recommended)
export BUILD_VM_CORES="4"                   # CPU cores (4 recommended for faster builds)
export BUILD_VM_DISK_SIZE="50G"             # Disk size (50GB minimum for build artifacts)
export BUILD_VM_STORAGE="local-lvm"         # Storage for build VM (use NVMe/SSD for speed)
export BUILD_VM_BRIDGE="vmbr0"              # Network bridge
export BUILD_VM_IP=""                       # Static IP (leave empty for DHCP auto-detection)

# The build VM IP will be auto-detected and saved after deployment
# Or set manually if you know the IP address in advance
#
# IMPORTANT: The deployment script will check if BUILD_VM_ID already exists
# (as either a VM or Container) and ask for confirmation before destroying/recreating

# ====================
# GITHUB SSH KEYS
# ====================

# GitHub username for SSH key import (leave empty to skip)
# SSH keys will be imported for both root and syslog users
# Example: export GITHUB_USERNAME="yourusername"
export GITHUB_USERNAME=""

# ====================
# STORAGE CONFIGURATION
# ====================

export STORAGE_POOL="nvme-pool"
export DATA_DISK_SIZE="1000G"  # Size of each data disk (4 per VM)
export MON_DISK_SIZE="100G"    # Size of mon disk (1 per VM)

# ====================
# NETWORK CONFIGURATION
# ====================

export PRIVATE_BRIDGE="vmbr1"  # Private/cluster network
export PUBLIC_BRIDGE="vmbr0"   # Public/client network

# ====================
# VM DEFAULT SETTINGS
# ====================

# Memory (in MB)
# Examples:
#   8GB  = 8192
#   16GB = 16384
#   32GB = 32768
#   64GB = 65536
export VM_DEFAULT_MEMORY="32768"

# CPU cores per VM
export VM_DEFAULT_CORES="8"
export VM_DEFAULT_SOCKETS="1"
export VM_CPU_TYPE="host"

# VM behavior
export AUTO_START="true"

# Root password for VMs (used during KIWI image build and cloud-init)
# IMPORTANT: Change this from the default for production use!
# This password is baked into the KIWI image and used for initial VM access
export VM_ROOT_PASSWORD="opensuse"

# Number of VMs to deploy (1-4)
export NUM_VMS="4"

# ====================
# CEPH CONFIGURATION
# ====================

# Ceph version (squid=19.2.x, reef=18.2.x, quincy=17.2.x)
export CEPH_VERSION="squid"

# Ceph admin node (first VM by default)
# This node will be used to bootstrap the cluster
export CEPH_ADMIN_NODE="ceph-node1"

# Ceph cluster network (private network for OSD replication)
# Auto-detected from VM private bridge (vmbr1) if not set
# export CEPH_CLUSTER_NETWORK="192.168.1.0/24"

# Ceph public network (client access network)
# Auto-detected from VM public bridge (vmbr0) if not set
# export CEPH_PUBLIC_NETWORK="192.168.0.0/24"

# Ceph deployment options
export CEPH_SKIP_MONITORING="true"      # Skip Prometheus/Grafana (can enable later)
export CEPH_SKIP_DASHBOARD="false"      # Install Ceph dashboard
export CEPH_ALLOW_FQDN="true"           # Allow FQDN hostnames

# ====================
# INDIVIDUAL VM CONFIGURATION
# ====================
# Uncomment and customize to override defaults for specific VMs

# VM1 Configuration
# export VM1_NAME="ceph-node1"
# export VM1_VMID="200"
# export VM1_MEMORY="16384"
# export VM1_CORES="4"
# export VM1_SOCKETS="1"
# export VM1_ONBOOT="1"
# export VM1_IP="192.168.1.100"

# VM2 Configuration
# export VM2_NAME="ceph-node2"
# export VM2_VMID="201"
# export VM2_MEMORY="16384"
# export VM2_CORES="4"
# export VM2_SOCKETS="1"
# export VM2_ONBOOT="1"
# export VM2_IP="192.168.1.101"

# VM3 Configuration
# export VM3_NAME="ceph-node3"
# export VM3_VMID="202"
# export VM3_MEMORY="16384"
# export VM3_CORES="4"
# export VM3_SOCKETS="1"
# export VM3_ONBOOT="1"
# export VM3_IP="192.168.1.102"

# VM4 Configuration
# export VM4_NAME="ceph-node4"
# export VM4_VMID="203"
# export VM4_MEMORY="16384"
# export VM4_CORES="4"
# export VM4_SOCKETS="1"
# export VM4_ONBOOT="1"
# export VM4_IP="192.168.1.103"

# ====================
# CONFIGURATION EXAMPLES
# ====================

# Small Development Cluster
# export VM_DEFAULT_MEMORY="8192"   # 8GB
# export VM_DEFAULT_CORES="4"
# export DATA_DISK_SIZE="500G"
# export NUM_VMS="3"

# Production Cluster (DEFAULT ABOVE)
# export VM_DEFAULT_MEMORY="32768"  # 32GB (already set as default)
# export VM_DEFAULT_CORES="8"       # (already set as default)
# export DATA_DISK_SIZE="2000G"
# export NUM_VMS="4"

# High-Performance Cluster
# export VM_DEFAULT_MEMORY="65536"  # 64GB
# export VM_DEFAULT_CORES="16"
# export DATA_DISK_SIZE="4000G"

# Mixed VM Sizes
# export VM_DEFAULT_MEMORY="16384"
# export VM_DEFAULT_CORES="4"
# export VM1_MEMORY="32768"   # VM1: 32GB
# export VM1_CORES="8"        # VM1: 8 cores
# export VM3_MEMORY="65536"   # VM3: 64GB
# export VM3_CORES="16"       # VM3: 16 cores
